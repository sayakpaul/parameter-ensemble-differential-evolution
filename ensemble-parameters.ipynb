{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766ee3e3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df792b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import configs\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b3801",
   "metadata": {},
   "source": [
    "## Initialize the configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = configs.get_model_config(\n",
    "    dataset_name=\"cifar10\", num_classes=10, image_size=32, path=\".\"\n",
    ")\n",
    "dataset_config = run_config[\"dataset_config\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b4b3a",
   "metadata": {},
   "source": [
    "## Prepare the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = run_config[\"batch_size\"]\n",
    "(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_ds = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f232fa0f",
   "metadata": {},
   "source": [
    "## Initialize model and populate checkpoints\n",
    "\n",
    "Download the checkpoints from here and then unzip:\n",
    "\n",
    "```shell\n",
    "$ wget https://github.com/sayakpaul/parameter-ensemble-differential-evolution/releases/download/v0.1.0/run-files.zip\n",
    "$ unzip -q run-files.zip\n",
    "```\n",
    "\n",
    "Or you can train two networks:\n",
    "\n",
    "```shell\n",
    "$ for i in `seq 1 2`; python train.py; done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt_paths = tf.io.gfile.glob(\"*-cifar10\")\n",
    "sorted(model_ckpt_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87be39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one = models.get_shallow_cnn(run_config)\n",
    "model_one.load_weights(tf.train.latest_checkpoint(model_ckpt_paths[0]))\n",
    "\n",
    "model_two = models.get_shallow_cnn(run_config)\n",
    "model_two.load_weights(tf.train.latest_checkpoint(model_ckpt_paths[1]))\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd3262",
   "metadata": {},
   "source": [
    "## Ensemble without differential evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf42177",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembled_model = models.get_shallow_cnn(run_config)\n",
    "ensembled_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\"\n",
    ")\n",
    "ema = 0.01\n",
    "\n",
    "for i in range(len(ensembled_model.layers)):\n",
    "    if hasattr(ensembled_model.layers[i], \"kernel\") and (\n",
    "        hasattr(ensembled_model.layers[i], \"bias\")\n",
    "    ):\n",
    "        ensembled_weights = (\n",
    "            model_one.layers[i].kernel * ema + (1 - ema) * model_two.layers[i].kernel\n",
    "        )\n",
    "\n",
    "        ensembled_bias = (\n",
    "            model_one.layers[i].bias * ema + (1 - ema) * model_two.layers[i].bias\n",
    "        )\n",
    "\n",
    "        ensembled_model.layers[i].kernel.assign(tf.Variable(ensembled_weights))\n",
    "        ensembled_model.layers[i].bias.assign(tf.Variable(ensembled_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = ensembled_model.evaluate(test_ds)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb429d1",
   "metadata": {},
   "source": [
    "## Ensemble with differential evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(ema_factor, members, test_ds):\n",
    "    ensembled_model = models.get_shallow_cnn(run_config)\n",
    "    ensembled_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\"\n",
    "    )\n",
    "\n",
    "    for i in range(len(ensembled_model.layers)):\n",
    "        if hasattr(ensembled_model.layers[i], \"kernel\") and (\n",
    "            hasattr(ensembled_model.layers[i], \"bias\")\n",
    "        ):\n",
    "            ensembled_weights = (\n",
    "                members[0].layers[i].kernel * ema\n",
    "                + (1 - ema) * members[1].layers[i].kernel\n",
    "            )\n",
    "\n",
    "            ensembled_bias = (\n",
    "                members[0].layers[i].bias * ema_factor\n",
    "                + (1 - ema_factor) * members[1].layers[i].bias\n",
    "            )\n",
    "\n",
    "            ensembled_model.layers[i].kernel.assign(tf.Variable(ensembled_weights))\n",
    "            ensembled_model.layers[i].bias.assign(tf.Variable(ensembled_bias))\n",
    "\n",
    "    _, accuracy = ensembled_model.evaluate(test_ds, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def loss_evolution(ema_factor, members, test_ds):\n",
    "    return 1.0 - evaluate_model(ema_factor, members, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://machinelearningmastery.com/weighted-average-ensemble-for-deep-learning-neural-networks/\n",
    "members = [model_one, model_two]\n",
    "\n",
    "search_arg = (members, test_ds)\n",
    "result = differential_evolution(\n",
    "    loss_evolution, bounds=[(0, 1)], args=search_arg, maxiter=1000, tol=1e-7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"EMA factor found using differential evolution: {result['x']}.\")\n",
    "accuracy = evaluate_model(result[\"x\"], members, test_ds)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f17db",
   "metadata": {},
   "source": [
    "## Scoring a randomly initialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembled_model = models.get_shallow_cnn(run_config)\n",
    "ensembled_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\"\n",
    ")\n",
    "\n",
    "_, accuracy = ensembled_model.evaluate(test_ds)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93f4b3",
   "metadata": {},
   "source": [
    "## Scores of the individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in members:\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\"\n",
    "    )\n",
    "\n",
    "    _, accuracy = model.evaluate(test_ds)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc19087",
   "metadata": {},
   "source": [
    "## Classic ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b45398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://machinelearningmastery.com/model-averaging-ensemble-for-deep-learning-neural-networks/\n",
    "def ensemble_predictions(members):\n",
    "    yhats = [model.predict(test_ds.map(lambda x, y: x)) for model in members]\n",
    "    yhats = np.array(yhats)\n",
    "    summed = np.sum(yhats, axis=0)\n",
    "    result = np.argmax(summed, axis=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "result = ensemble_predictions(members)\n",
    "\n",
    "y_true = []\n",
    "for _, label in test_ds.unbatch():\n",
    "    y_true.append(label)\n",
    "\n",
    "accuracy = accuracy_score(y_true, result)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
